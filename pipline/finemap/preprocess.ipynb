{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas_file = \"/home/xutingfeng/GIFT/data/GWAS/T1Mapping_Cortex_20240129.csv_firstorder_Median_all_2023_GRCh38_unionKidneys.tsv.gz\"\n",
    "# bfile_path = \"/home/xutingfeng/GIFT/data/bgen/DNAJC16\"\n",
    "bfile_path = \"/mnt/d/桌面/work/GIFT/data/pgen/DNAJC16_GRCh38\"\n",
    "\n",
    "bgen_path = f\"{bfile_path}.bgen\"\n",
    "sample_path = f\"{bfile_path}.sample\"\n",
    "bgi_path = f\"{bfile_path}.bgen.bgi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locus_region: 1:15333355-15833355\n"
     ]
    }
   ],
   "source": [
    "from finemap_tools.reader.gwas import load_GWASFormated_file\n",
    "\n",
    "\n",
    "topLoci = (1, 15583355, 15583355)  # (chr, start, end)\n",
    "locus_range = 250  # 100kb\n",
    "locus_range = locus_range * 1000\n",
    "locus_range_tuple = (topLoci[0], topLoci[1] - locus_range, topLoci[2] + locus_range)\n",
    "\n",
    "locus_region = f\"{locus_range_tuple[0]}:{locus_range_tuple[1]}-{locus_range_tuple[2]}\"\n",
    "print(f\"locus_region: {locus_region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/home/xutingfeng/GIFT/data/analysis/DNAJC16/FINEMAP\"\n",
    "from pathlib import Path\n",
    "\n",
    "Path(save_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from finemap_tools.utils import add_ID\n",
    "import numpy as np\n",
    "\n",
    "zfile_gwasformated_map = {\n",
    "    \"rsid\": None,\n",
    "    \"chromosome\": \"chrom\",\n",
    "    \"position\": \"pos\",\n",
    "    \"allele1\": \"ref\",  # allele1 is the first allele of bgen, and mostly is the ref allele in UKB or others, but plz check.\n",
    "    \"allele2\": \"alt\",  # allele2 is the second allele of bgen, and mostly is the alt allele in UKB or others, but plz check.\n",
    "    \"maf\": None,\n",
    "    \"beta\": \"beta\",\n",
    "    \"se\": \"sebeta\",\n",
    "}\n",
    "\n",
    "\n",
    "def to_zfile(sumstats: pd.DataFrame, cols_map: dict = None):\n",
    "\n",
    "    used_col_map = zfile_gwasformated_map.copy()\n",
    "    if cols_map is not None:\n",
    "        used_col_map.update(cols_map)\n",
    "\n",
    "    if used_col_map.get(\"rsid\", None) is None:\n",
    "        sumstats[\"rsid\"] = add_ID(\n",
    "            sumstats,\n",
    "            [\n",
    "                used_col_map[\"chromosome\"],\n",
    "                used_col_map[\"position\"],\n",
    "                used_col_map[\"allele1\"],\n",
    "                used_col_map[\"allele2\"],\n",
    "            ],\n",
    "            new_col=\"rsid\",\n",
    "        )\n",
    "\n",
    "        used_col_map[\"rsid\"] = \"rsid\"\n",
    "\n",
    "    if used_col_map.get(\"maf\", None) is None:\n",
    "        freq_col = used_col_map.get(\"freq_col\", \"af\")  # default freq_col is \"af\"\n",
    "        if freq_col not in sumstats.columns:\n",
    "            raise ValueError(\n",
    "                f\"freq_col: {freq_col} not in gwas columns , freq_col or maf must be passed \"\n",
    "            )\n",
    "        sumstats[freq_col] = sumstats[freq_col].astype(float)\n",
    "        sumstats[\"maf\"] = np.where(\n",
    "            sumstats[freq_col] < 0.5, sumstats[freq_col], 1.0 - sumstats[freq_col]\n",
    "        )\n",
    "\n",
    "        used_col_map[\"maf\"] = \"maf\"\n",
    "\n",
    "    rename_cols = {\n",
    "        v: k for k, v in used_col_map.items() if k in zfile_gwasformated_map.keys()\n",
    "    }\n",
    "    sumstats = sumstats.rename(columns=rename_cols)\n",
    "    return sumstats[list(rename_cols.values())]\n",
    "\n",
    "\n",
    "from finemap_tools.snpfilter import filter_pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabix have a header, so will take the first line as header and remove it.\n",
      "drop 463 ambiguous alleles\n",
      "drop 10 biallelic snps\n"
     ]
    }
   ],
   "source": [
    "sumstats = load_GWASFormated_file(gwas_file, region=locus_region)  # load\n",
    "sumstats[\"variant_id\"] = add_ID(sumstats, [\"chrom\", \"pos\", \"ref\", \"alt\"])  # add rsid\n",
    "sumstats = filter_pipline(sumstats=sumstats, id_col=\"variant_id\")  # filter\n",
    "zfile = to_zfile(sumstats, cols_map={\"rsid\": \"variant_id\"})  # to zfile format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all in bgen file\n",
    "try:\n",
    "    import hail as hl\n",
    "\n",
    "    hl.init()\n",
    "except:\n",
    "    pass\n",
    "# # TODO:contig_recoding may need to update\n",
    "try:\n",
    "    data = hl.import_bgen(bgen_path, entry_fields=[], sample_file=sample_path)\n",
    "except:\n",
    "    hl.index_bgen(bgen_path, contig_recoding={\"1\": \"chr1\"}, reference_genome=\"GRCh38\")\n",
    "    data = hl.import_bgen(bgen_path, entry_fields=[], sample_file=sample_path)\n",
    "\n",
    "bgen_var = data.rows().to_pandas()\n",
    "before_merge_nums = len(zfile)\n",
    "zfile = zfile[zfile[\"rsid\"].isin(bgen_var[\"rsid\"])]\n",
    "after_merge_nums = len(zfile)\n",
    "print(\n",
    "    f\"before merge nums: {before_merge_nums}, after merge nums: {after_merge_nums}, droped nums: {before_merge_nums - after_merge_nums}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from finemap_tools.utils import iter_count\n",
    "\n",
    "# sample_tgt_path = os.path.join(save_d\n",
    "n_sample = iter_count(sample_path) - 2\n",
    "\n",
    "tgt_bgen = os.path.join(save_dir, \"data.bgen\")\n",
    "tgt_sample = os.path.join(save_dir, \"data.sample\")\n",
    "tgt_bgi = os.path.join(save_dir, \"data.bgen.bgi\")\n",
    "tgt_z = os.path.join(save_dir, \"data.z\")\n",
    "\n",
    "\n",
    "# for bgen link data\n",
    "try:\n",
    "    os.symlink(bgen_path, tgt_bgen)\n",
    "    os.symlink(sample_path, tgt_sample)\n",
    "    os.symlink(bgi_path, tgt_bgi)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "zfile.to_csv(tgt_z, sep=\" \", index=False, na_rep=\"NA\")\n",
    "\n",
    "\n",
    "header_list = [\n",
    "    \"z\",\n",
    "    \"bgen\",\n",
    "    \"bgi\",\n",
    "    \"sample\",\n",
    "    \"bcor\",\n",
    "    \"bdose\",\n",
    "    \"ld\",\n",
    "    \"n_samples\",\n",
    "    \"snp\",\n",
    "    \"config\",\n",
    "    \"cred\",\n",
    "    \"log\",\n",
    "]\n",
    "file_list = [\n",
    "    \"data.z\",\n",
    "    \"data.bgen\",\n",
    "    \"data.bgen.bgi\",\n",
    "    \"data.sample\",\n",
    "    \"data.bcor\",\n",
    "    \"data.bdose\",\n",
    "    \"data.ld\",\n",
    "    n_sample,\n",
    "    \"data.snp\",\n",
    "    \"data.config\",\n",
    "    \"data.cred\",\n",
    "    \"data.log\",\n",
    "]\n",
    "\n",
    "\n",
    "with open(os.path.join(save_dir, \"data\"), \"w\") as f:\n",
    "    for write_list in [header_list, file_list]:\n",
    "        f.write(\";\".join([str(x) for x in write_list]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487409"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "zfile.to_csv(\n",
    "    f\"/home/xutingfeng/GIFT/data/analysis/DNAJC16/FINEMAP/dataset.z\",\n",
    "    sep=\" \",\n",
    "    index=False,\n",
    "    na_rep=\"NA\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bgen import BgenReader, BgenWriter\n",
    "\n",
    "bfile = BgenReader(bgen_path)\n",
    "rsids = bfile.rsids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = bfile[10]\n",
    "\n",
    "var.probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(487409, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var.probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a variant by indexing\n",
    "var = bfile[1000]\n",
    "\n",
    "# pull out genotype probabilities\n",
    "probs = var.probabilities  # returns 2D numpy array\n",
    "dosage = var.minor_allele_dosage  # returns 1D numpy array for biallelic variant\n",
    "\n",
    "# iterate through every variant in the file\n",
    "with BgenReader(BGEN_PATH, delay_parsing=True) as bfile:\n",
    "    for var in bfile:\n",
    "        dosage = var.minor_allele_dosage\n",
    "\n",
    "# get all variants in a genomic region\n",
    "variants = bfile.fetch(\"21\", 10000, 5000000)\n",
    "\n",
    "# or for writing bgen files\n",
    "import numpy as np\n",
    "from bgen import BgenWriter\n",
    "\n",
    "geno = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]).astype(np.float64)\n",
    "with BgenWriter(BGEN_PATH, n_samples=3) as bfile:\n",
    "    bfile.add_variant(\n",
    "        varid=\"var1\",\n",
    "        rsid=\"rs1\",\n",
    "        chrom=\"chr1\",\n",
    "        pos=1,\n",
    "        alleles=[\"A\", \"G\"],\n",
    "        genotypes=geno,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"cb71ffaa-39be-4148-a062-a3908620655a\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"cb71ffaa-39be-4148-a062-a3908620655a\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.4.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"cb71ffaa-39be-4148-a062-a3908620655a\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import hail as hl\n",
    "\n",
    "# hl.init()\n",
    "from hail.plot import show\n",
    "from pprint import pprint\n",
    "\n",
    "hl.plot.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing Hail with default parameters...\n",
      "your 131072x1 screen size is bogus. expect trouble\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/13 20:28:19 WARN Utils: Your hostname, DESKTOP-JUVLFQO resolves to a loopback address: 127.0.1.1; using 172.18.33.194 instead (on interface eth0)\n",
      "24/03/13 20:28:19 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "24/03/13 20:28:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "Running on Apache Spark version 3.3.4\n",
      "SparkUI available at http://172.18.33.194:4040\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.128-eead8100a1c1\n",
      "LOGGING: writing to /home/xutingfeng/github_code/mine/finemap_tools/pipline/finemap/hail-20240313-2028-0.2.128-eead8100a1c1.log\n",
      "2024-03-13 20:28:23.300 Hail: INFO: downloading 1KG VCF ...\n",
      "  Source: https://storage.googleapis.com/hail-tutorial/1kg.vcf.bgz\n",
      "2024-03-13 20:28:27.456 Hail: INFO: importing VCF and writing to matrix table...\n",
      "2024-03-13 20:28:28.386 Hail: INFO: scanning VCF for sortedness...\n",
      "2024-03-13 20:28:31.289 Hail: INFO: Coerced sorted VCF - no additional import work to do\n",
      "2024-03-13 20:28:33.212 Hail: INFO: wrote matrix table with 10879 rows and 284 columns in 16 partitions to data/1kg.mt\n",
      "2024-03-13 20:28:33.250 Hail: INFO: downloading 1KG annotations ...\n",
      "  Source: https://storage.googleapis.com/hail-tutorial/1kg_annotations.txt\n",
      "2024-03-13 20:28:34.223 Hail: INFO: downloading Ensembl gene annotations ...\n",
      "  Source: https://storage.googleapis.com/hail-tutorial/ensembl_gene_annotations.txt\n",
      "2024-03-13 20:28:36.290 Hail: INFO: Done!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
